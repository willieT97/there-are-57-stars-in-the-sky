<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>The Fall of the Information Age</title>
  <link rel="stylesheet" href="/style.css" />

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1BWWHSSFGC"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1BWWHSSFGC');
</script>
</head>
<body>
  <header>
    <nav>
      <a href="/index.html">Home</a>
      <a href="/blog.html">Blog</a>

    </nav>
    <span class="typed-text">Blog</span>
  </header>

  <main>
    <article class="blog-post">
      <h1>The Fall of the Information Age</h1>
      <p class="post-date">Posted on July 21, 2025</p>

      <h1>Introduction</h1>
<p>A video came across my instagram feed recently that stopped me in my tracks. The ‘Prompt Theory’ video which was powered by Veo3 ai video generator.
    <div class="video-container">
  <iframe 
    src="https://www.youtube.com/embed/buKJQBExUy8" 
    title="Prompt Theory"
    frameborder="0" 
    allowfullscreen>
  </iframe>
</div>

<style>
  .video-container {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
  }

  .video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
</style>

In this video, the characters are in disbelief of the ‘prompt theory’. A theory of how none of them are real and they are simply powered by prompts. This is completely made by an Ai text to video generator. The video shows what appears to be scenes with various actors and sets. However, there are no actors, there are no sets, just code. I showed this video to my younger sister and she asked, “how can we trust anything that we see now?”. How indeed. We have been quietly living in what is called The Information Age for almost 100 years. A time when the transmissibility of valuable information progressed continuously. Ai is the spoke in the wheel of the information age. This comes at a time when our historical information institutions seem to be crumbling.</p>

      <h1>Lack of new information</h1>
<img src="FOIA-pics/Newspaper-decline.png" alt="Newspaper decline 1950-2010" class="float-image">
<style>
  .float-image {
    float: right;               /* Push image to the left */
    margin: 0 15px 15px 0;     /* Space around image: top, right, bottom, left */
    width: 400px;              /* Optional: set image size */
    border-radius: 8px;        /* Optional: rounded corners */
  }
</style>
<p>The old information systems are defunct in our modern world. Newspapers, radio, even television have been on a steady decline over the past <a href="http://media-cmi.com/downloads/Sixty_Years_Daily_Newspaper_Circulation_Trends_050611.pdf" class="hover-box-link">decade</a>. The smart phone has effectively replaced
all of them, and with it a new culture of information
has grown. This is the culture of click-bate, where attention is valued above all. As a result of this many newspapers, television networks, and radio networks have adopted the policy of, ‘if you can’t beat them join them’. The space for slow paced, deep, long form media has to a large extent disappeared, although some space remains in the podcast/audiobook world. The space for investigative journalism has been squeezed out as the need for constant clicks and algorithm
 
adherence steers media companies towards quantity over quality. The mechanisms for keeping politicians, private companies, or drug cartels in line, i.e. through deep investigative journalism have been weakened. This type of journalism may take months or years of investigation without an article being written. Influencers and institutions clamouring for attention at all times, so nobody has time for that.</p>

      <h1>Corruption of Science</h1>
<img src="FOIA-pics/Scientific-articles.png" alt="Rise of academic articles" class="float-image">
<style>
  .float-image {
    float: right;               /* Push image to the left */
    margin: 0 15px 15px 0;     /* Space around image: top, right, bottom, left */
    width: 400px;              /* Optional: set image size */
    border-radius: 8px;        /* Optional: rounded corners */
  }
</style>
<p>Another avenue by which we acquire new information is scientific research. Unfortunately scientific research has become increasingly unreliable for two main reasons; 
<p>1. The publish or perish model of research.</p>
<p>2. The ease with which data can now be falsified.</p>
The economic system by which universities and scientific journals stay afloat requires papers to be churned out rapidly. From these papers, universities gain grant funding. Journals are paid per article published, not by the quality. The amount of scientific papers published has exploded and so has the workload of scientists to produce such <a href="https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science" class="hover-box-link">papers</a>. The primary goal of producing a scientific paper is shifting slowly away from communicating interesting findings, and towards appealing to grant funders. There have been many data, and plagiarism scandals at elite universities over the past couple of years to show <a href="https://pubmed.ncbi.nlm.nih.gov/38087103/" class="hover-box-link">this.</a>
</p>

        <h1>The Harvard scandal and other such scandals.</h1>

<p>The curious case of Francisco Gino comes to mind. The post-doctoral researcher at Harvard, studying honesty and ethical behaviour who was shown to have falsified data on said <a href="https://www.theguardian.com/education/2025/may/27/harvard-professor-on-leave-falsified-ethics-data" class="hover-box-link">research.</a> 

This came amid allegations of plagiarism directed at Claudine Gay, Harvards President at the time had plagiarised some of her research. These incidences both occurred at Harvard, and both within a year. It is easy to see these cases as individual academics taking the easy ways out, but perhaps we can see this in light of a systemic pressure to produce article after article. The number of fraudulent articles has grown massively in the last few years and is having a hugely negative impact on the scientific <a href="https://pubmed.ncbi.nlm.nih.gov/38087103/" class="hover-box-link">community.</a>
</p>

        <h1>Paper Mills</h1>
<img src="FOIA-pics/Papers-meme.png" alt="Rise of academic articles" class="float-image">
<style>
  .float-image {
    float: right;               /* Push image to the left */
    margin: 0 15px 15px 0;     /* Space around image: top, right, bottom, left */
    width: 400px;              /* Optional: set image size */
    border-radius: 8px;        /* Optional: rounded corners */
  }
</style>
<p>Due to the publish or perish model that has festered in scientific institutions. We have seen a rise in <a href="https://www.theguardian.com/technology/2018/aug/10/predatory-publishers-the-journals-who-churn-out-fake-science" class="hover-box-link"> ‘paper mills’.</a> These journals will publish fake science for a <a href="https://pmc.ncbi.nlm.nih.gov/articles/ PMC11582211/#:~:text=Abstract" class="hover-box-link"> profit.</a>
These paper mills survive as a result of a rot that has settled in academic science.
Science is slowly falling into the trappings that the scientific method was designed to avoid. These are, the trappings of money and authority bias. Scientific institutions earn a lot of money from subscription fees to their <a href="https://library.hkust.edu.hk/sc/academic-publishing-amazing-profit/#:~:text=Academic%20publishing%20has%20long%20been,which%20had%20only%20about%2022%." class="hover-box-link"> journals.</a>
Because universities don’t want to have gaps in
          
their libraries, they are in effect forced to subscribe to them. As a result, scientific journals are incentivised to churn out journals, reducing the quality and needlessly taking time away from the actual <a href="https://www.cbc.ca/news/science/academic-publishers-reap-huge-profits-as-libraries-go-broke-1.3111535#:~:text=" class="hover-box-link"> research.</a>
Scientific institutions are reliant on this model or they will be forced to shut down. The economics by which science survives is anathema to the scientific method. What does this do to our corpus of knowledge?
</p>

            <h1>Personal Experience</h1>
      <p>When I saw the ‘Prompt Video’, the world felt different. Our informational systems seemed to be on the decline for some time, but this was a seismic shift in the way that we must process information. This allows for fabricating videos which are almost indistinguishable from real videos. With ChatGPT, the same is true for written text. Would you know if the book your reading was written by ChatGPT? Certainly, colleges are having a hard time parsing essays for Ai generated <a href="https://www.theguardian.com/education/2025/jun/15/thousands-of-uk-university-students-caught-cheating-using-ai-artificial-intelligence-survey" class="hover-box-link"> content.</a>
Ai models such as ChatGPT (a large language model), Veo3(a text to video generator), and various Ai audio generators change our paradigm. Our relationship to information, visual, audio, text... have been changed so profoundly that it will take generations to truly understand it.</p>

            <h1>Information Age vs. ChatGPT</h1>
      <p>The transition for computers for calculation purposes, to home computers, to internet, to smart phones has been a story of the freeing of information. This information could be generally sourced for reliability if necessary. ChatGPT also produces information very quickly, however, it performs more like an oracle, conjuring information from the ether. With our previous informational systems, the source of the information was a human. A human did the work, and if that human had fabricated data, this would stain their reputation. With ChatGPT this is not so. Because of the model that ChatGPT is based on it splices and sometimes invents information and data. SampleQA, a test that checks for hallucinations (times when information is inaccurate) found that GPT4.5, the latest model hallucinates 37.1% of the <a href="https://openai.com/index/introducing-gpt-4-5/" class="hover-box-link"> time.</a> This does not fully jive with our experience of using the model as these tests are designed to test the model. For everyday tasks, I have found ChatGPT to be more than 37.1% reliable, however, the general impression that it gives near perfect answers almost all the time is far from true. We need to know what we are dealing with when interacting with ChatGPT.</p>

            <h1>Cheapening of information</h1>
      <p>It is interesting what psychological impact this exposure to a seemingly endless oracle of information has on us. It is shown to be often inaccurate, however that is not our perception, as that is not how the information is presented. ChatGPT would never say, ‘I’m not really sure about the following’. It tends to confident even when it is wayward. We believe what it tells us. It feels like magic. However it does not uncover new information. It only collates information that already exists and explain it in a way that information is already explained. However our perception of it as an oracle damages our stream of new information in two ways;
<p>1. When free information is presented as fact, we tend to believe that we need not spend money
on ensuring that the source of our information is good.</p>
<p>2. We feel that there is no point spending money on investigative journalism as anything of note
will be spat out with the right prompt.</p>
<p>Both of these assumptions, although very natural are incorrect.</p>

            <h1>On ChatGPT Information is Probabilistic</h1>
             <div class="video-container">
  <iframe 
    src="https://www.youtube.com/embed/h6NqcRdIHVM" 
    title="ChatGPT based on probabilities"
    frameborder="0" 
    allowfullscreen>
  </iframe>
</div>

<style>
  .video-container {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
  }

  .video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
</style>
      <p>As we interact with ChatGPT our relationship to information changes. This is because the relationship that LLMs(The technology that ChatGPT is based on) themselves have to information is entirely different from our own. LLMs are trained on huge amounts of data like books, internet articles, blogs... from this they learn to predict sentences. Because the datasets which they are strained on are so huge, theoretically, the LLM will converge on truth and coherent <a href="https://arxiv.org/html/2401.02038v2/#S3" class="hover-box-link">answers.</a> For simple everyday tasks, this is almost always true. It is a great replacement for googling silly
things. However on higher order tasks, tasks with a small existing dataset, it can fly off the rails
 quickly.</p>

        <h1>Optimise for credibility rather than truth</h1>
 <p>These models are language models, both in name and function. They are not truth models. They have not been trained to be the most accurate regurgitaters of information. They have been trained to communicate in a way that is credible and <a href="https://link.springer.com/article/10.1007/s43681-023-00315-3" class="hover-box-link"> human-like</a>. We need to understand this if we are going to use LLMs for tasks. The LLM is not designed to help you in your pursuit of truth, although it can do that in many domains. It is designed to communicate like a person. It is designed to convince you that there is someone behind the curtain. They are designed to pass the Turing test. They have been trained to convince, and they are incredibly good at this, better than <a href="https://phys.org/news/2025-05-chatgpt-shown-persuasive-people-online.html" class="hover-box-link"> us</a>.</p>

        <h1>Inaccuracies</h1>
<img src="FOIA-pics/Ai-meme.png" alt="Ai-meme" class="float-image">
<style>
  .float-image {
    float: right;               /* Push image to the left */
    margin: 0 15px 15px 0;     /* Space around image: top, right, bottom, left */
    width: 400px;              /* Optional: set image size */
    border-radius: 8px;        /* Optional: rounded corners */
  }
</style>
        
 <p>As mentioned previously, the newest model of ChatGPT has a hallucination rate of 37.1%. This is high, and with certain tasks, especially ones involving logic this rate goes up. The problem with the hallucinations of ChatGPT is not just that it is producing inaccurate information, but also that it does so convincingly. If you have ever encountered a hallucination directly, as I have before while researching, you almost feel as if you are being gaslit. In my experience, it has shown fake sources, with fake authors and fake institutions. When I looked the paper up, I thought I must be doing something wrong here. The I looked up the authors. They proved to be non existent. ChatGPT is a powerful tool when
    
used correctly, but to use it correctly we must understand what it is and what it is not.</p>

    <h1>Interactability</h1>
<p>With LLMs we are essentially trading interactability and convenience for accuracy and traceability. This can have very positive effects.This interactive relationship with information means that we can learn more quickly and easily. If I am reading a book and I don’t understand something I will have to reread, look up some words, or simply move on. However, on ChatGPT, I can ask further questions which will be answered. This is much more like human-to-human learning. It also has an ability to produce material extremely quickly. Open ChatGPT and type the following prompt;<a href="https://chatgpt.com/c/687f5890-d304-8328-9a73-3bd963eb913a" class="hover-box-link"> ‘Give a summery of the Dubliners by James Joyce as told by a modern day dubliner in a pub’.</a> The answer is in many ways breathtaking and allows for more accessibility to certain types of information. The problem is that these systems also produce misinformation extraordinarily cheaply, quickly and easily. Try typing the following into chatgpt;<a href="https://chatgpt.com/c/687f5890-d304-8328-9a73-3bd963eb913a" class="hover-box-link"> ‘can you produce an article in the style of a scientific journal which shows that clowns don't cry.’</a> Although this is a harmless example, it is easy to see how this would be misused. Unfortunately we already see examples of misuse.</p>

    <h1>Studies on effects of ChatGPT on brain function</h1>
<p>Studies on the effects of using LLMs such as ChatGPT are coming out and they do not show positive results. They find that use of ChatGPT reduces brain activity and over time got <a href="https://time.com/7295195/ai-chatgpt-google-learning-school/" class="hover-box-link"> lazier.</a> This is not a surprising finding. It is a simple case of use it or lose it. If we outsource thinking, we will lose our ability to think. If we lose our ability to think, we will find it very difficult to do deep research, whether that be scientific research or journalistic research. <a href="https://cheirif.wordpress.com/wp-content/uploads/2014/08/hannah-arendt- the-origins-of-totalitarianism-meridian-1962.pdf" class="hover-box-link"> “The ideal subject of totalitarian rule is not the convinced Nazi or the convinced Communist, but people for whom the distinction between fact and fiction... no longer exists.” - Hannah Arendt, ‘The Origins of Totalitarianism’ p.474</a>
</p>

<h1>Ai produced content</h1>
<p>Like the hallucinations mentioned earlier, convincing misinformation can be produced intentionally using ChatGPT. Papers can be produced with fake data. Unless a huge amount of fact checking is done it is almost impossible to distinguish real from <a href="https://theconversation.com/chatgpt-just-passed-the-turing-test-but-that-doesnt-mean-ai-is-now-as-smart-as-humans-253946" class="hover-box-link"> fake.</a> There are attempts to check for the use of Ai in essays but they are not very good. There are many things that Ai is good at and the number 1 thing is convincing you of the reality of its outputs. ChatGPT behave much like an incredibly complex version of predictive text. It predicts what one would say in response to your <a href="https://futurism.com/altman-please-thanks-chatgpt?utm_source=chatgpt.com" class="hover-box-link"> questions.</a> It predicts what outputs would look most human-like. 
It is for this reason that many believe in a theory called the dead internet theory.
</p>

<h1>Dead Internet Theory</h1>
<div class="video-container">
  <iframe 
    src="https://www.youtube.com/embed/D2rp-SVIGKI" 
    title="Dead Internet Theory"
    frameborder="0" 
    allowfullscreen>
  </iframe>
</div>

<style>
  .video-container {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
  }

  .video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
</style>
<p>The ‘Dead Internet Theory’ is a theory which states that the material on the internet is mostly produced by Ai bots. This includes, web pages, blog posts, YouTube videos, to commenters on Reddit... This is a theory that is gaining popularity due to some high profile cases of Ai bots posing as humans, such as the
‘The Velvet Sundown’, an Ai generated band circulating on <a href="https://www.theguardian.com/ technology/2025/jul/14/an-ai-generated-band-got-1m-plays-on-spotify-now-music-insiders-say- listeners-should-be-warned" class="hover-box-link"> Spotify.</a> 
This is a deep theory with many layers, which perhaps I will do a blog post on one day. The simple verdict on ‘Dead Internet Theory’ is that the internet is neither fully human nor fully Ai generated. Very informative, I know. It is extremely difficult to evaluate how much is one or the other and I think this belies the problem of the time we are living in. I am attaching some links in case you (yes you, the reader) have a spare 10 hours to jump down a rabbit hole;
<p><a href="https://nymag.com/intelligencer/2018/12/how-much-of-the-internet-is-fake.html" class="hover-box-link">Dead Internet</a></p>
<p><a href="https://www.theatlantic.com/technology/archive/2017/01/bots-bots-bots/515043/" class="hover-box-link">Bots</a></p>
<p><a href="https://gizmodo.com/facebooks-twisted-incentives-created-its-ai-slop-era-2000484110 Brainrot content for kids https://www.nytimes.com/interactive/2018/08/11/technology/youtube-fake-view-sellers.html" class="hover-box-link">Brainrot</a></p>
<p><a href="https://www.forbes.com/sites/chriswestfall/2025/01/02/meta-opens-floodgates-on-ai-generated-accounts-on-facebook-instagram/" class="hover-box-link">Ai Accounts</a></p>
<p><a href="https://www.reddit.com/r/skeptic/comments/1fy7b5e/can_anyone_explain_dr_egon_cholakians_the_impact/" class="hover-box-link">Egon Cholakian</a></p>
<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0160791X23000672" class="hover-box-link">Algorithmic Radicalisation</a></p>


<h1>Test with travel blogs</h1>
<img src="FOIA-pics/Nomadic-Matt.png" alt="Nomadic Matt" class="float-image">
<style>
  .float-image {
    float: right;               /* Push image to the left */
    margin: 0 15px 15px 0;     /* Space around image: top, right, bottom, left */
    width: 400px;              /* Optional: set image size */
    border-radius: 8px;        /* Optional: rounded corners */
  }
</style>
        
<p>The world of internet research can make your head spin. Before you know it you start falling into these rabbit holes left and right. Before you know it, you’ll believe that the world is a frisbee. To keep myself grounded I like to perform little experiments from myself. I will start with a simple question; How many of the top travel blogs can I tied to real people. I know that this is not a scientific way to test this. It is more of a sanity check for me. So after looking up travel blogs on google and removing duplicates I was left with: Cassidy travel
<p>Effitimonholiday</p>
<p>Travel Department</p>
<p>Nomadic Matt</p>
<p>Click and go</p>
<p>Turquoise holidays</p>
<p>TDactive holidays</p>
<p>Abbey travel</p>
<p>After extensively diving into each blog, finding authors names, and doing research on each of these authors I was only able to tie 3 of the authors to anything that would substantiate their identity, Facebook, Instagram, LinkedIn, or a photograph on google images. These were Nomadic Matt, Gaby Coughlan from Turquoise Holidays, and Bridget Delany from Travel Department. This doesn’t necessarily tell me much, but at least there are some real people on the travel blog side of the internet.
</p>

<h1>It’s the Vibes Man</h1>
<p>The ‘Dead Internet Theory’ started with people on internet forums discussing how the ‘vibes’ of the internet were <a href="https://forum.agoraroad.com/index.php?threads/dead-internet-theory-most-of-the-internet-is-fake.3011/" class="hover-box-link">off.</a> The internet was not the same as it was before. It used to be a place to converse and make connections with people. This side of the internet had slowly faded, leaving a void. When we are starved for real information, vibes is all we have left to make inferences about the world. Our growing use of ‘vibes’ to judge the world is proof that we are starved of real, quality information. This is not an accident. There is money to be made from controlling information, controlling narratives, and of course convincing people to buy rubbish that they don’t need.</p>

<h1>Consumerism and Ai</h1>
<p>The power of marketing in the modern day is to convince you that the new thing, is somehow better than the thing you already have. It is to spin us into a frenzy of consumerism, retail therapy, and false promises. Many analogies can be drawn to the recent advancements in LLMs. Their real power is in convincing. No matter how suspect the present information is, it is terrifically <a href="https://phys.org/news/2025-05-chatgpt-shown-persuasive-people-online.html" class="hover-box-link"> convincing.</a>
It is easy to predict how these models may be used in the advertising industry to further advance the interest of consumerists. This will even further subjugate those who are already prayed upon by the advertising <a href="https://www.linkedin.com/pulse/consumer-culture-social-economic-impact-consumerism-riya-bhorkar-7gakc/" class="hover-box-link"> industry.</a></p>

<h1>Parallels to Consumerism</h1>
<p>One cannot help but notice the the matching trend of this technological development and the trend of consumerism in our culture. The story of ChatGPT is a story of the swelling of information. Quantity over quality. It is a story of convenience. 1 well made wooden bucket replaced by 15 easily broken but also easily replaced plastic buckets. A few personal or well crafted videos replaced by a seemingly infinite hole of Ai generated videos. The kids call these ‘brain rot’, quite an apt description. Interacting with a real person on the internet, replaced by an attractive but hollow facsimile. Interestingly, the people at ChatGPT saw fit, to design one of their voice models after Scarlet Johansson from the movie <a href="https://www.nytimes.com/2024/05/14/technology/ai-chatgpt-her-movie.html" class="hover-box-link"> ‘Her’.</a> I don’t think, they understood this movie.</p>

<h1> Grok Debacle</h1>
<div class="video-container">
  <iframe 
    src="https://www.youtube.com/embed/BvmnOGx6crs" 
    title="Grok"
    frameborder="0" 
    allowfullscreen>
  </iframe>
</div>

<style>
  .video-container {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
  }

  .video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
  }
</style>
<p>Elon Musk’s new Ai experiment ‘Grok’ had a surprising turn a couple of weeks ago. It began to align itself with Nazi views, condoned Hitler, and began calling itself <a href="https://www.politico.com/news/magazine/2025/07/10/musk-grok-hitler-ai-00447055" class="hover-box-link"> ‘MechaHitler’.</a> This is a ridiculous but also very telling case study in how these LLMs can be used for evil. In this episode the hate spewed by Grok was so obvious that it was treated as a laughing stock. But what happens when the hate or propaganda becomes more subtle and harder to detect. People by the millions, or potentially billions could be manipulated in accordance with the whims of the people who control these systems.</p>

<h1>Lack of accountability and transparency</h1>
<p>The dominion over information that the dictators or monarchs of the past has was being eroded by the freeing of information in the Information Age. It is difficult to pinpoint exactly when this started to reverse itself. When was it that tech moguls and state forces began to realise that if they united, that none of them would have to be held accountable. Case Study: Suchir Balaji, deceased whistleblower, such a common phrase that has become. A whistleblower who dies by suicide just before they are due to give evidence. Suchir Balaji was a former employee of OpenAI, the parent company of ChatGPT, he was a researcher tasked with training the Ai with large datasets. However he noticed that much of the data used to train the model was <a href="https://www.mondaq.com/unitedstates/new-technology/1576584/openai-whistleblower-death-deemed-suspicious-by-some-will-it-impact-evidence-admissible-in-pending-copyright-cases" class="hover-box-link"> copyrighted.</a> He brought this up internally and subsequently sought to bring it to court. In between filing the motion and giving evidence, he shot himself at a very strange <a href="https://www.dailymail.co.uk/news/article-14577547/Suchir-Balaji-bombshell-claims-bullet-wounds-autopsy.html" class="hover-box-link"> angle.</a> The San Fransisco Police Department and the Chief Medical Examiner concluded that it was a suicide.</p>

<h1>Targeted information</h1>
<p>The algorithm is this mystical thing that the average consumer has no understanding of. There is a Kafkaesque nature to it. This thing will rule your life, or at least your online life, but you have no understanding of it, no knowledge of how it works, and no ability to change it. In the mystical world of ‘the algorithm’, the general public is clueless. The wool can be pulled over our eyes so easily, and what can we do about it? How would you know if a social media company is targeting videos to intentionally make you have a pathological level of self doubt. How would you know if ChatGPT was censoring certain information, how would you know if a celebrity video was actually made with deep fake technology, how would we know if social media companies are intentionally manipulating people. In fact we know that some of these are with out a doubt <a href="https://www.pnas.org/doi/full/10.1073/pnas.1320040111" class="hover-box-link"> true.</a> </p>

<h1>What is real?</h1>
<p>We are in a new era. That has happened. Information is nebulous and can be easily fabricated. The institutions with control over our informational systems are shrouded in secrecy. They are difficult to question and even if we could question them, we wouldn’t understand how they work. We as a people need to understand how not in control we are. I live in a democratic country, but in effect the world as we know it is not even close to democracy, no matter where you live. In order for there to be a democracy, the populous must be well informed. We are controlled through our screens 6hours and <a href="https://backlinko.com/screen-time- statistics#" class="hover-box-link"> 38mins per day</a>. Big tech companies have so much data on the average <a href="https://www.yorku.ca/ research/its/wp-content/uploads/sites/728/2023/02/ITS-Policy-Briefing-01-2023-Personal-Data- Governance.pdf" class="hover-box-link"> person.</a>
Text, articles, who websites can be fabricated quickly and easily. Videos, which were once the highest form of evidence (probably still are) can be fabricated quickly and easily. What and who can we trust? How do we prevent ourselves from being manipulated.</p>

<h1>Authoritarianism and abusive relationships</h1>
<p>In 2022 Merriam-Webster named ‘gaslighting’ their <a href="https://www.merriam-webster.com/wordplay/word-of-the-year-2022" class="hover-box-link"> Word of the Year.</a> How prescient this was. Not only because we became increasingly aware of the non-physical aspects of domestic abuse and abuse of other kinds, but also because gaslighting is integral to authoritarianism. We have seen this very clearly in the past week, as Donald Trump attempts to gaslight the world into ignoring a predatory child-sex trafficking ring involving some of the most powerful people in the world, which was potentially used for blackmailing and possibly has ties to intelligence <a href="https://www.youtube.com/watch?v=RozK1FcbxLI" class="hover-box-link"> agencies.</a>  Trump announced, <a href=https://www.pbs.org/newshour/politics/trump-slams-supporters-who-are-angered-over-epstein-case-as-weaklings" class="hover-box-link"> ’Their new SCAM is what we will forever call the Jeffrey Epstein Hoax’</a> on Truth Social.
      
The reason why gaslighting is so necessary to perpetuate abuse is become the abuse victim must doubt the truth of what they <a href="https://www.medicalnewstoday.com/articles/gaslighting" class="hover-box-link"> see.</a> We are empathetic creatures, when we are gaslit, our emotional and logical circuits are at odds, we are paralysed by cognitive dissonance. In the wake of this paralysis, the abuser/authoritarian seizes control.
</p>

<h1>Perception and Beliefs</h1>
<p>As the coffers of information become more opaque, what is the regular person supposed to do? They become increasingly dependant on the new systems, while paradoxically becoming less aware of where this information comes from. They read articles written by LLMs, watch TV shows generated by Ai video processing, and consume news which uses both. How are they to know what is true? How are they to know what is real? The people who have the levers of power in this world, not only control material goods, or institutions. They control the world at the level of perception.
This is exacerbated by the fact that our perception is far more malleable that we would like to <a href="https://www.nature.com/articles/d43978-023-00080-1" class="hover-box-link"> believe.</a>
The feeling that we have that we are observing the objective world through our eyes is an illusion. Sight is itself subjective.</p>

<h1>Beliefs</h1>
<p>When information fully deserts us, when we have been stripped of our knowledge of the world and it’s happenings, what do we have left? We have the only thing that can never be taken from us, that is our deepest beliefs and our spiritual connection. When I say our spiritual connection, I do not mean our knowledge of the Bible, the Talmud or the Qur’an. I mean that sense that is within us all that transcends intellectuality which tells you what is right and what is wrong. They cannot take that from us, though they may try. Because we will be starved of falsifiable information, we will be left to simply choose what to belief or disbelieve in. We must choose wisely.</p>

    </article>
  </main>

  <footer>
    <div class="terminal-comments">
      <textarea class="terminal-input" placeholder="Type your comment here..." rows="3"></textarea>
      <button class="terminal-submit" onclick="submitComment()">Submit</button>
      <pre id="comment-output" class="comment-log"></pre>
    </div>
  </footer>

  <script>
    function submitComment() {
      const input = document.querySelector('.terminal-input');
      const output = document.getElementById('comment-output');
      const comment = input.value.trim();

      if (!comment) {
        alert('Please enter a comment.');
        return;
      }

      const time = new Date().toLocaleTimeString();
      output.textContent += `[${time}] > ${comment}\n`;

      input.value = '';
      output.scrollTop = output.scrollHeight;
    }
  </script>
</body>
</html>
